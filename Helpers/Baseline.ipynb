{"cells":[{"cell_type":"markdown","source":["## Load essentials"],"metadata":{"colab_type":"text","id":"8xrkxnNhcBtO"}},{"cell_type":"code","source":["#Importing data packages\nimport pandas as pd\nimport numpy as np\nimport mlflow\n\nimport nltk\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize, sent_tokenize \nimport sklearn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nnltk.download('stopwords')\nnltk.download('punkt')\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\nnltk.download('wordnet')\n\n# Load libraries\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier"],"metadata":{"id":"uGO2I4rxap5T","colab_type":"code","outputId":"9fe76281-404b-4ef3-8fe9-a65c62205da0","colab":{}},"outputs":[],"execution_count":2},{"cell_type":"code","source":["%run /Meetings/helpers/Test_Model"],"metadata":{"colab_type":"code","id":"-LIwbtzxcLdG","colab":{}},"outputs":[],"execution_count":3},{"cell_type":"code","source":["%run /Meetings/helpers/Data_Creation"],"metadata":{"id":"3SIV70VgfOGP","colab_type":"code","colab":{}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["##Random Forest"],"metadata":{"colab_type":"text","id":"sh5HWP7PckhX"}},{"cell_type":"markdown","source":["###DTM"],"metadata":{"colab_type":"text","id":"ZQU8fWb2dbNn"}},{"cell_type":"code","source":["def create_dtm(dataframe, columnname):\n  vec = TfidfVectorizer()\n  X = vec.fit_transform(dataframe[columnname])\n  dtm = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n  return vec, dtm"],"metadata":{"id":"73B8MLhgap7a","colab_type":"code","colab":{},"outputId":"e4bb0ec6-9070-4adc-a4dc-5edce5fa7bf5"},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["###Classifier"],"metadata":{"colab_type":"text","id":"6oXVf1Scde8v"}},{"cell_type":"code","source":["def splitdata_rf(dtm, labeldf, labelcolumn):\n  # Using Skicit-learn to split data into training and testing sets\n  # Split the data into training and testing sets\n  train_features, test_features, train_labels, test_labels = train_test_split(dtm, labeldf.iloc[:,labelcolumn], test_size = 0.20, random_state = 42)\n  return train_features, test_features, train_labels, test_labels"],"metadata":{"colab_type":"code","id":"xM5zr0lmcLjB","colab":{},"outputId":"718174eb-5353-4246-88cc-8ef97090e9d8"},"outputs":[],"execution_count":9},{"cell_type":"code","source":["def randomforest(dtm, labeldf, labelcolumn):\n  train_features, test_features, train_labels, test_labels = splitdata_rf(dtm, labeldf, labelcolumn)\n  #Train classifier \n  randomforest = RandomForestClassifier(n_estimators=10, random_state=0, verbose=3)  \n  randomforest.fit(train_features, train_labels)  \n  #Predict test set labels\n  y_pred = randomforest.predict(test_features)  \n  from sklearn import metrics\n  # --classification report --\n  report = metrics.classification_report(test_labels, y_pred, labels=[0,1])\n  print(report)\n  return randomforest, y_pred, report"],"metadata":{"id":"sM4YpMgYap8M","colab_type":"code","colab":{},"outputId":"c6b4e196-76e3-461c-bd55-038177f336c7"},"outputs":[],"execution_count":10},{"cell_type":"code","source":["def create_baseline(dataframe, textcolumnname, labelcolumn):\n  vec, dtm = create_dtm(dataframe, textcolumnname)\n  rfmodel, predictions, report = randomforest(dtm, dataframe, labelcolumn)\n  return vec, rfmodel, predictions, report"],"metadata":{"id":"M-6zfTwMfOIx","colab_type":"code","colab":{},"outputId":"455326cb-857e-48bc-b155-71f596c82666"},"outputs":[],"execution_count":11},{"cell_type":"code","source":["def predict_rf(rfmodel, dataframe, textcolumn, vec):\n  featurevector = vec.transform(dataframe.iloc[:,textcolumn])\n  y_pred = rfmodel.predict_proba(featurevector)  \n  return y_pred"],"metadata":{"id":"baiRz_ypfOI0","colab_type":"code","colab":{},"outputId":"c7865031-9bc7-44ee-a5a0-7e5a9d88c539"},"outputs":[],"execution_count":12},{"cell_type":"code","source":["def predictions_df_rf(meeting, t, ground_truth, df):\n  \n  df = df.append({'Summary_ID': meeting + 1, 'Prediction': t, 'Ground Truth': ground_truth}, ignore_index=True)\n  return df"],"metadata":{"id":"lgOu1pnbfOI3","colab_type":"code","colab":{},"outputId":"f065823c-be89-42c4-cb3e-1e4ee47a192a"},"outputs":[],"execution_count":13},{"cell_type":"code","source":["def create_predictions_rf(meeting, dataframe, rfmodel, vec, dftest, summary_table, threshold):\n  dftest  = dftest[dftest['Meeting ID'] == meeting + 1]\n  dftest.iloc[:,3] = dftest.iloc[:,3].astype(str)\n\n  predictions = predict_rf(rfmodel, dftest, 2, vec)\n  \n  #Create transcript based on predictions and threshold\n  scores = ['none'] * len(predictions)\n  labels = [0] * len(predictions)\n  \n  \n  for i in range(len(predictions)):\n    scores[i] = predictions[i][1]\n    if scores[i] > threshold:\n      labels[i] = 1\n  \n  dftest['Predicted'] = labels\n  transcript = dftest.Transcript[dftest.Predicted == 1]\n  \n  #Concatenate all transcript sentences\n  transcript = pd.DataFrame(transcript)\n  t = \"\"\n  \n  for i in range(len(transcript)):\n    t = t + str(transcript.iloc[i,0]) + \" \"\n  \n  #Grab original summary\n  ami_df = table_to_df(summary_table)\n  ground_truth = ami_df.iloc[meeting,3]\n  dataframe = predictions_df(meeting, t, ground_truth, dataframe)\n  return dataframe\n"],"metadata":{"id":"0TibR5ZZfOI7","colab_type":"code","colab":{},"outputId":"b67d1bae-447a-4ad1-b41c-4127c7abfe2e"},"outputs":[],"execution_count":14},{"cell_type":"code","source":["def test_model_rf(rfmodel, dftest, reload, summary_table, start, stop, threshold, vec):\n  if reload == True:\n    dftest = load_test(summary_table, start, stop)\n  \n  df_prediction = pd.DataFrame(columns=['Summary_ID', 'Prediction', 'Ground Truth'])\n\n  for i in range(start,stop):\n    df_prediction = create_predictions_rf(i, df_prediction, rfmodel, vec, dftest, summary_table, threshold)\n  \n  hypotheses = df_prediction.iloc[:,1].values\n  ground_truth = df_prediction.iloc[:,2].values\n  \n  log_array = calculate_rouge(hypotheses, ground_truth)\n  \n  return dftest, df_prediction, log_array"],"metadata":{"id":"d_yvNYaTfOJA","colab_type":"code","colab":{},"outputId":"19559783-1262-4e53-9376-310f4a324114"},"outputs":[],"execution_count":15}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.0","nbconvert_exporter":"python","file_extension":".py"},"name":"Baseline","notebookId":3552432870093679,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"name":"Baseline.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["5n32-aG5_AWA","V0keNvZJcJ26","pl7EQevscTvi","DR8aD2azcZf5","k98riy8cZyan","93MMXX4VHMxr","hW74QNVQHXIq","l3ia6QsvpEHW","VA5_a6-dnc_i","sh5HWP7PckhX","tg1PtUs0aR6s"]}},"nbformat":4,"nbformat_minor":0}
