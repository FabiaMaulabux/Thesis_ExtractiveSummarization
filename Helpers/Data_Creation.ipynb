{"cells":[{"cell_type":"code","source":["#Copied from fastai notebook\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\n#Importing data packages\nimport pandas as pd\nimport numpy as np\n\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize, sent_tokenize \nimport sklearn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()"],"metadata":{"id":"c5S1TvO27PPB","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">%matplotlib inline is not supported in Databricks.\nYou can display matplotlib figures using display(). For an example, see https://docs.databricks.com/user-guide/visualizations/matplotlib-and-ggplot.html\n</div>"]}}],"execution_count":1},{"cell_type":"markdown","source":["##Data Creation"],"metadata":{"id":"r38S7lkrfVHS","colab_type":"text"}},{"cell_type":"code","source":["def table_to_df(table_name):\n  table = spark.sql(\"select * from \" + table_name)\n  df = table.toPandas()\n  return df"],"metadata":{"id":"OVJDuP75fJKq","colab_type":"code","colab":{}},"outputs":[],"execution_count":3},{"cell_type":"code","source":["def prep_df(df):\n  df.iloc[:,2] = df.iloc[:,2].astype(str)\n  df.iloc[:,3] = df.iloc[:,3].astype(str)\n  df.loc[df.Label == 'neg', 'Label'] = 0\n  df.loc[df.Label == 'pos', 'Label'] = 1\n  df.iloc[:,3] = df.iloc[:,3].astype(int)\n  return df"],"metadata":{"id":"mt_PHmJNfJKv","colab_type":"code","colab":{}},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#Select transcript and corresponding summary of one meeting, split by sentence and make list\ndef isolate(row, df): \n  from nltk.tokenize import word_tokenize, sent_tokenize \n  transcript = sent_tokenize(df.iloc[row,1])\n  summary = sent_tokenize(df.iloc[row,3])\n  return transcript, summary"],"metadata":{"id":"MrOzDMv_TlbF","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["#Compare each transcript sentence with all summary sentences to find match\ndef Assign_Label(transcript, summary):\n  value = 'neg'\n  for j in range(len(summary)):\n    if transcript == summary[j]:\n      value = 'pos'\n    else:\n      continue\n  return value"],"metadata":{"id":"dZD_jrfc6x9l","colab_type":"code","colab":{}},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#function to preprocess and tokenize text files\nimport nltk \nWPT = nltk.WordPunctTokenizer()\n#nltk.download('stopwords')\n#nltk.download('punkt')\n#nltk.download('wordnet')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\nstop_word_list = nltk.corpus.stopwords.words('english')\n\ndef BOW(list):\n    '''Remove numbers and special characters in sentence'''\n    import re\n    list = re.sub(\" \\d+\", \" \", list) #digits\n    list = re.sub(r'[0-9]+', \"\",list) #digits\n    list = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", list)\n    pattern = r\"[{}]\".format(\"-_)(;:$%#.\") #special characters\n    list = re.sub(pattern, \"\", list) \n    list = re.sub(r\"[\\']\", \"\",list)\n    list = re.sub(r\"[/']\", \"\",list)\n    list = re.sub(r'\\b[a-zA-Z]\\b', '', list) #remove single letter words\n    list = re.sub('\\s+', ' ', list).strip() #remove double spaces\n    '''Lowercase'''\n    list = list.lower()\n    list = list.strip()\n    '''Tokenize'''\n    tokens = WPT.tokenize(list)\n    filtered_tokens = [token for token in tokens if token not in stop_word_list]\n    sentence_length = len(filtered_tokens)\n    \n    '''Lem'''\n    k = []\n    for word in range(len(filtered_tokens)):\n        k.append(lemmatizer.lemmatize(filtered_tokens[word]))\n    list = ' '.join(k)\n    return list"],"metadata":{"id":"SXm6E4uFUShb","colab_type":"code","colab":{}},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#Calculate TF-IDF per unique word in one transcript and calculate the sum per sentence (TF-IDF on sentence level score)\ndef Assign_Score(tokenized):\n  import numpy as np\n  import sklearn\n  from sklearn.feature_extraction.text import TfidfVectorizer\n  vectorizer = TfidfVectorizer()\n  X = vectorizer.fit_transform(tokenized)\n  X = X.sum(axis = 1)\n  X = np.asarray(X)\n  return X"],"metadata":{"id":"kgvcSDuYmu_I","colab_type":"code","colab":{}},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#Calculate length of tokens in tokenized sentence\ndef Calculate_Len(sentence):\n  sentence_length = word_tokenize(sentence)\n  sentence_length = len(sentence_length)\n  return sentence_length\n"],"metadata":{"id":"9U9VO8hJILBy","colab_type":"code","colab":{}},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#Add all collected values for 1 transcript to dataframe \ndef Append_DF (df, m_id, transcript, label, score):\n  import pandas as pd\n  from sklearn import preprocessing\n  print('Loading values for meeting ' + str(m_id))\n  for i in range(len(transcript)):\n    transcript2 = [BOW(item) for item in transcript]\n    length = Calculate_Len(transcript2[i])\n      \n    df = df.append({'Meeting ID': m_id,'Transcript': transcript[i], 'Tokenized': transcript2[i],'Label': label[i],'Length': length, 'Score': score[i][0]}, ignore_index=True)\n\n    #Print progress \n    if i == round((1/2 * len(transcript))):\n        print('Loaded 1/2 of meeting ' + str(m_id))\n    \n    if i == ((len(transcript) - 1)):\n      print('Loaded 2/2 of meeting ' + str(m_id))\n      \n  x = df[['Length']].values.astype(float)\n  min_max_scaler = preprocessing.MinMaxScaler()\n  length = min_max_scaler.fit_transform(x)\n  for i in range(len(df)):\n    df.iloc[i,4] = length[i][0]\n\n  x = df[['Score']].values.astype(float)\n  min_max_scaler = preprocessing.MinMaxScaler()\n  score = min_max_scaler.fit_transform(x)\n  for i in range(len(df)):\n    df.iloc[i,5] = score[i][0]\n    \n  return df"],"metadata":{"id":"WH8AHhk7hDuS","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["#Loop over all transcript to collect values and return dataframe \ndef load_sentences(df_original, df_new, start, stop):\n  import pandas as pd\n  for i in range(start, stop):\n    transcript, summary = isolate(i, df_original)\n    transcript2 = [BOW(item) for item in transcript]\n    label = [Assign_Label(transcript, summary) for transcript in transcript]\n    score = Assign_Score(transcript2)\n    df_new = Append_DF(df_new, i + 1, transcript, label, score)\n  print(\"Completed loading \" + str(stop) + \" meetings to dataframe \" + str(df_new))\n  return df_new"],"metadata":{"id":"FGfSeQn34pZq","colab_type":"code","colab":{}},"outputs":[],"execution_count":11}],"metadata":{"colab":{"name":"Data_Creation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"name":"Data_Creation","notebookId":2828187062111384},"nbformat":4,"nbformat_minor":0}
